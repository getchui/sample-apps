# Trueface SDK Python Bindings Sample App
## Face Recognition RTSP Server
This sample app demonstrates how to consume an RTSP stream, decode the frames, run face recognition and annotate the frames, then re-encode those frames as x264 and stream the result over RTSP.

## Prerequisites
- Start by reading the `README.md` file [here](../README.md) for instructions on how to download the SDK and add the SDK to your environment.
Be sure to download the GPU enabled SDK for this sample app.
- `pip3 install opencv-python`
- `sudo apt-get install libgstreamer1.0-0 gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio`
- `sudo apt-get install libglib2.0-dev libgstrtspserver-1.0-dev gstreamer1.0-rtsp`

## Project Overview
- `enroll_in_database.py` - This script demonstrates how to use the Trueface SDK to enroll face recognition templates into a collection. 
This script must be run before running the main application. Open and modify the script to use your own enrollment images and identities.
- `run_1_n_identification_rtsp_server.py` - This is the main application which consumes the RTSP stream, runs face recognition, then restreams the results. 
The application loads the collection previously generated by `enroll_in_database.py` and runs face recognition queries against that. The application usese gstreamer to support a variable output frame rate, which allows us to run face recognition on all the detected faces in the image. 
- `run_1_n_identification_rtsp_server.sh` - Demonstrates how to run the python script with the required arguments. 

## Running the Demo
- Start by modifying `enroll_in_database.py` to enroll your own images into a collection. Next, run the script: `python3 enroll_in_database.py`. This will create a SQLite database file called `my_database.db`.
- Next, edit `run_1_n_identification_rtsp_server.sh` and change `--input_rtsp_stream` to your input RTSP URL.
- Next, run the main application by running `./run_1_n_identification_rtsp_server.sh`. Wait until `Ready to accept connections...` is printed in your console, at which point you are ready to make a connection to the RTSP stream.
- Open up VLC, go to `Media > Open Network Stream...` then enter `rtsp://localhost:8554/trueface_stream`. At this point, you should be able to view the annotated RTSP stream. The stream tends to freeze initially, but give it some time and it should be working again.  

## Demo
The stream on the left is the input RTSP stream, the stream on the right is the output RTSP stream.
Variable frame rate is demonstrated when the there are multiple detected faces in the image (because we must generate a FR feature vector for each detected face, which increses the processing time). 

https://user-images.githubusercontent.com/17056751/118336033-c1eca300-b4c5-11eb-851a-0571e2ac410f.mp4



## Notes
- The RTSP stream may freeze initially, give it a few minutes to stabilize.
- Using an input stream with smaller dimensions will result in better performance. If the output stream is very slow and lags a lot, try scaling down the input video.
- If running the app on a device such as an NVIDIA Jetson, you may need to replace `self.cap = cv2.VideoCapture(source)` with something like the following:
```
gstreamer_pipeline_string = 'rtspsrc location="{}" ! rtph264depay ! h264parse ! omxh264dec ! videoconvert ! appsink'.format(source)
self.cap = cv2.VideoCapture(gstreamer_pipeline_string)
```